---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# finetune

<!-- badges: start -->
[![Codecov test coverage](https://codecov.io/gh/tidymodels/finetune/branch/master/graph/badge.svg)](https://codecov.io/gh/tidymodels/finetune?branch=master)
[![R build status](https://github.com/tidymodels/finetune/workflows/R-CMD-check/badge.svg)](https://github.com/tidymodels/finetune/actions)
<!-- badges: end -->

`finetune` contains some extra functions for model tuning that extend what is currently in the `tune` package. 

Very rough version of the package right now but it works fairly well. There are two main sets of tools. 

Tuning via _simulated annealing_ optimization is another iterative search tool for finding good values: 

```{r sa}
library(tidymodels)
library(finetune)

# Syntax very similar to `tune_grid()` or `tune_Bayes()`: 

## -----------------------------------------------------------------------------

data(two_class_dat, package = "modeldata")

set.seed(6376)
rs <- bootstraps(two_class_dat, times = 10) # more resamples usually needed

# optimize an regularized discriminant analysis model
library(discrim)
rda_spec <-
  discrim_regularized(frac_common_cov = tune(), frac_identity = tune()) %>%
  set_engine("klaR")

## -----------------------------------------------------------------------------

set.seed(8300)
sa_res <- 
  rda_spec %>% 
  tune_sim_anneal(Class ~ ., resamples = rs, iter = 20, initial = 4)
show_best(sa_res, metric = "roc_auc", n = 2)
```

The second set of methods are for "racing". We start off by doing a small set of resamples for all of the grid points, then statistically testing to see which ones should be dropped or investigated more. The two methods here are based on those should in [Kuhn (2014)](https://arxiv.org/abs/1405.6974). 

For example, using an ANOVA-type analysis to filter out parameter combinations:

```{r race}
set.seed(511)
grid <-
  rda_spec %>%
  parameters() %>%
  grid_max_entropy(size = 20)

set.seed(11)
grid_anova <- rda_spec %>% tune_race_anova(Class ~ ., resamples = rs, grid = grid)
show_best(grid_anova, metric = "roc_auc", n = 2)
```

`tune_race_win_loss()` can also be used. 


## Code of Conduct
  
Please note that the finetune project is released with a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.
